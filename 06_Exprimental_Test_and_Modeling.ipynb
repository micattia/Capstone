{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micattia/Capstone/blob/master/06_Exprimental_Test_and_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHFqffosQo0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load pandas component for data science\n",
        "import pandas as pd\n",
        "\n",
        "#load Apple data \n",
        "linkAP1 = 'https://raw.githubusercontent.com/micattia/Capstone_Data/master/AppleFinalData.csv'\n",
        "dfAPPL = pd.read_csv(linkAP1)\n",
        "linkAP2 = 'https://raw.githubusercontent.com/micattia/Capstone_Data/master/AppleNewsStock.csv'\n",
        "dfAPPLnews = pd.read_csv(linkAP2)\n",
        "\n",
        "#load Microsoft data\n",
        "linkMS1 = 'https://raw.githubusercontent.com/micattia/Capstone_Data/master/MicrosoftFinalData.csv'\n",
        "dfMS = pd.read_csv(linkMS1)\n",
        "linkMS2 = 'https://raw.githubusercontent.com/micattia/Capstone_Data/master/MicrosoftNewsStock.csv'\n",
        "dfMSnews = pd.read_csv(linkMS2)\n",
        "\n",
        "# Changing Some column names for the Microsoft main data frame to:\n",
        "# 1- removed the space from the Adj Close column, so that it would not give errors with coding\n",
        "# 2- standarised all columns to start with caps lock.\n",
        "\n",
        "dfMS = dfMS.rename(index=str, columns={\"Adj Close\": \"Adj_Close\", \"compound\": \"Compound\", \"neg\": \"Neg\", \"neu\": \"Neu\", \"pos\": \"Pos\"})\n",
        "\n",
        "# Changing Some column names for the Apple main data frame to:\n",
        "# 1- removed the space from the Adj Close column, so that it would not give errors with coding\n",
        "# 2- standarised all columns to start with caps lock.\n",
        "\n",
        "dfAPPL = dfAPPL.rename(index=str, columns={\"Adj Close\": \"Adj_Close\", \"compound\": \"Compound\", \"neg\": \"Neg\", \"neu\": \"Neu\", \"pos\": \"Pos\"})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmfYH4buQu4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading required libraries \n",
        "#==========================\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.plotly as py\n",
        "import plotly.figure_factory as ff\n",
        "%matplotlib inline\n",
        "\n",
        "plt.style.use('ggplot')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvDEqui5Pg6Z",
        "colab_type": "code",
        "outputId": "6ce39ef6-5f04-4f89-a820-4ddcf5973778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "# Building a simple linier regression model and show its generated linier formula\n",
        "# removed the Close variable from the dataset since it is the same value as the Adj_Close dependant variable\n",
        "# which will lead to always have 100% accuracy\n",
        "\n",
        "from statsmodels.formula.api import ols\n",
        "model = ols('Adj_Close ~ Open + High + Low + Compound + Neg + Neu + Pos', data=dfMS)\n",
        "model = model.fit()\n",
        "print(model.params)\n",
        "#print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intercept   -0.007568\n",
            "Open        -0.524203\n",
            "High         0.760597\n",
            "Low          0.764195\n",
            "Compound    -0.005027\n",
            "Neg         -0.018313\n",
            "Neu         -0.000197\n",
            "Pos         -0.017996\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXCWV3wAPpnG",
        "colab_type": "code",
        "outputId": "375f3dd8-a92e-4b8a-96a2-27a487db18ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:              Adj_Close   R-squared:                       1.000\n",
            "Model:                            OLS   Adj. R-squared:                  1.000\n",
            "Method:                 Least Squares   F-statistic:                 8.886e+05\n",
            "Date:                Sun, 07 Jul 2019   Prob (F-statistic):               0.00\n",
            "Time:                        23:11:45   Log-Likelihood:                 410.96\n",
            "No. Observations:                2517   AIC:                            -805.9\n",
            "Df Residuals:                    2509   BIC:                            -759.3\n",
            "Df Model:                           7                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept     -0.0076      0.015     -0.495      0.621      -0.038       0.022\n",
            "Open          -0.5242      0.016    -32.035      0.000      -0.556      -0.492\n",
            "High           0.7606      0.014     52.598      0.000       0.732       0.789\n",
            "Low            0.7642      0.014     54.180      0.000       0.737       0.792\n",
            "Compound      -0.0050      0.020     -0.252      0.801      -0.044       0.034\n",
            "Neg           -0.0183      0.137     -0.134      0.894      -0.287       0.250\n",
            "Neu           -0.0002      0.013     -0.016      0.988      -0.025       0.025\n",
            "Pos           -0.0180      0.121     -0.149      0.881      -0.254       0.218\n",
            "==============================================================================\n",
            "Omnibus:                      339.193   Durbin-Watson:                   2.117\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3976.317\n",
            "Skew:                          -0.146   Prob(JB):                         0.00\n",
            "Kurtosis:                       9.151   Cond. No.                     2.43e+03\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 2.43e+03. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv_JYjwdvJfA",
        "colab_type": "code",
        "outputId": "e5d346e1-0de8-489b-81a7-6ded01421139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "# Using Anova test to compare between the two models where one have the financial data only \n",
        "# while the other have the sentiment analysis as well\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "\n",
        "model1 = ols('Adj_Close ~ Open + High + Low ', data=dfMS).fit()\n",
        "model2 = ols('Adj_Close ~ Open + High + Low + Compound + Neg + Neu + Pos', data=dfMS).fit()\n",
        "anova_result = anova_lm(model1, model2)\n",
        "print(anova_result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   df_resid         ssr  df_diff  ss_diff         F    Pr(>F)\n",
            "0    2513.0  106.338547      0.0      NaN       NaN       NaN\n",
            "1    2509.0  106.314047      4.0   0.0245  0.144548  0.965438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in greater\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in less\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:1892: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in less_equal\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe2vs0qFjg4K",
        "colab_type": "code",
        "outputId": "997e8a63-7f62-4a29-877f-f7581b49577e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        }
      },
      "source": [
        "################################ 1- SIMPLE LINEAR REGRESSION MODELS ######################################################\n",
        "################################################################################\n",
        "# MICROSOFT LINEAR TEST 1\n",
        "# BUILDING FIRST PREDECTION MODEL - SIMPLE LINIER REGRESSION\n",
        "# TEST GIVE 100% ACURACY WITH THE CLOSE COLUMN, AS IT IS THE SAME AS ADJ_CLOSE VALUE\n",
        "# SPLITING THE DATA INTO TRAINING SET AND TEST SET\n",
        "# THEN BUILDONG THE MODEL BASED ON THE TRAINING SET\n",
        "################################################################################\n",
        "from patsy import dmatrices\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.discrete.discrete_model as sm\n",
        "import statsmodels.api as sm1\n",
        "\n",
        "train_set, test_set = train_test_split(dfMS, train_size=0.7, random_state=1)\n",
        "\n",
        "y_train, X_train = dmatrices('Adj_Close ~ Open + High + Low + Close + Compound + Neg + Neu + Pos', train_set, return_type = 'dataframe')\n",
        "linier = sm1.OLS(y_train , X_train)\n",
        "linreg = linier.fit()\n",
        "linreg.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>Adj_Close</td>    <th>  R-squared:         </th>  <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>2.113e+31</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sun, 07 Jul 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>23:12:22</td>     <th>  Log-Likelihood:    </th>  <td>  52172.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>  1761</td>      <th>  AIC:               </th> <td>-1.043e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>  1752</td>      <th>  BIC:               </th> <td>-1.043e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>-1.057e-14</td> <td> 2.95e-15</td> <td>   -3.580</td> <td> 0.000</td> <td>-1.64e-14</td> <td>-4.78e-15</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Open</th>      <td>-3.275e-15</td> <td> 3.69e-15</td> <td>   -0.887</td> <td> 0.375</td> <td>-1.05e-14</td> <td> 3.96e-15</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>High</th>      <td> 1.277e-15</td> <td> 3.99e-15</td> <td>    0.320</td> <td> 0.749</td> <td>-6.55e-15</td> <td> 9.11e-15</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Low</th>       <td> 4.226e-15</td> <td> 3.94e-15</td> <td>    1.073</td> <td> 0.283</td> <td> -3.5e-15</td> <td> 1.19e-14</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Close</th>     <td>    1.0000</td> <td>  3.8e-15</td> <td> 2.63e+14</td> <td> 0.000</td> <td>    1.000</td> <td>    1.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Compound</th>  <td> 4.552e-15</td> <td> 3.87e-15</td> <td>    1.175</td> <td> 0.240</td> <td>-3.04e-15</td> <td> 1.21e-14</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Neg</th>       <td> 3.209e-14</td> <td> 2.68e-14</td> <td>    1.196</td> <td> 0.232</td> <td>-2.05e-14</td> <td> 8.47e-14</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Neu</th>       <td> -1.18e-15</td> <td> 2.42e-15</td> <td>   -0.488</td> <td> 0.626</td> <td>-5.92e-15</td> <td> 3.56e-15</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Pos</th>       <td>-1.788e-14</td> <td> 2.33e-14</td> <td>   -0.768</td> <td> 0.443</td> <td>-6.36e-14</td> <td> 2.78e-14</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>172.856</td> <th>  Durbin-Watson:     </th> <td>   0.305</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 226.887</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.879</td>  <th>  Prob(JB):          </th> <td>5.40e-50</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.997</td>  <th>  Cond. No.          </th> <td>2.86e+03</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.86e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:              Adj_Close   R-squared:                       1.000\n",
              "Model:                            OLS   Adj. R-squared:                  1.000\n",
              "Method:                 Least Squares   F-statistic:                 2.113e+31\n",
              "Date:                Sun, 07 Jul 2019   Prob (F-statistic):               0.00\n",
              "Time:                        23:12:22   Log-Likelihood:                 52172.\n",
              "No. Observations:                1761   AIC:                        -1.043e+05\n",
              "Df Residuals:                    1752   BIC:                        -1.043e+05\n",
              "Df Model:                           8                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept  -1.057e-14   2.95e-15     -3.580      0.000   -1.64e-14   -4.78e-15\n",
              "Open       -3.275e-15   3.69e-15     -0.887      0.375   -1.05e-14    3.96e-15\n",
              "High        1.277e-15   3.99e-15      0.320      0.749   -6.55e-15    9.11e-15\n",
              "Low         4.226e-15   3.94e-15      1.073      0.283    -3.5e-15    1.19e-14\n",
              "Close          1.0000    3.8e-15   2.63e+14      0.000       1.000       1.000\n",
              "Compound    4.552e-15   3.87e-15      1.175      0.240   -3.04e-15    1.21e-14\n",
              "Neg         3.209e-14   2.68e-14      1.196      0.232   -2.05e-14    8.47e-14\n",
              "Neu         -1.18e-15   2.42e-15     -0.488      0.626   -5.92e-15    3.56e-15\n",
              "Pos        -1.788e-14   2.33e-14     -0.768      0.443   -6.36e-14    2.78e-14\n",
              "==============================================================================\n",
              "Omnibus:                      172.856   Durbin-Watson:                   0.305\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              226.887\n",
              "Skew:                          -0.879   Prob(JB):                     5.40e-50\n",
              "Kurtosis:                       2.997   Cond. No.                     2.86e+03\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 2.86e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV83yqctqhgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREDECTING THE TEST SET BASED ON THE SIMPLE LINEAR REGRESSION MODEL CREATED BY THE TRAINING SET \n",
        "y_test, X_test = dmatrices('Adj_Close ~ Open + High + Low + Close + Compound + Neg + Neu + Pos', test_set, return_type = 'dataframe')\n",
        "pred = linreg.predict(X_test)\n",
        "#pred = model.get_prediction(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bgtj67UzOII",
        "colab_type": "code",
        "outputId": "c17bd0f7-8900-4284-a725-3449b7de2fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# EVALUATING THE MODEL\n",
        "# AND PLOT THE ERRORS\n",
        "errors = pred - test_set['Adj_Close']\n",
        "sns.distplot(errors,kde = False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEJCAYAAACaFuz/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMVjosWNmJNk",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL46MwGYzVc5",
        "colab_type": "code",
        "outputId": "a003cd83-9901-4553-cbd0-5dac949bab39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Calculating the root mean square errors \n",
        "# Calculating the percentage of cases with less than 5% error\n",
        "import math\n",
        "rmse = math.sqrt((errors **2).sum()/len(test_set))\n",
        "rel_change = errors.abs() / test_set['Adj_Close']\n",
        "pred05 = (rel_change < 0.05).sum() / len(test_set)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"PRED(05):\", pred05)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 3.295012163886266e-14\n",
            "PRED(05): 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32dJaLqdi_Gv",
        "colab_type": "code",
        "outputId": "793c6cba-50e7-4767-b241-0202b28b9e62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "################################################################################\n",
        "# MICROSOFT LINEAR TEST 2\n",
        "# TESTING DIFFRENT PREDECTION - SIMPLE LINIER REGRESSION\n",
        "# REMOVE CLOSE COLUMN AS IT IS THE SAME VALUE AS ADJ_CLOSE\n",
        "# TEST SHOWS WHEN REMOVING THE ACCURACY WAS DECREASED \n",
        "# SPLITING THE DATA INTO TRAINING SET AND TEST SET\n",
        "# THEN BUILDONG THE MODEL BASED ON THE TRAINING SET\n",
        "################################################################################\n",
        "#from patsy import dmatrices\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#import statsmodels.discrete.discrete_model as sm\n",
        "#import statsmodels.api as sm1\n",
        "\n",
        "train_set, test_set = train_test_split(dfMS, train_size=0.7, random_state=1)\n",
        "\n",
        "y_train, X_train = dmatrices('Adj_Close ~ Open + High + Low + Compound + Neg + Neu + Pos', train_set, return_type = 'dataframe')\n",
        "linier = sm1.OLS(y_train , X_train)\n",
        "linreg = linier.fit()\n",
        "linreg.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>Adj_Close</td>    <th>  R-squared:         </th> <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>6.119e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sun, 07 Jul 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>23:38:35</td>     <th>  Log-Likelihood:    </th> <td>  277.50</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>  1761</td>      <th>  AIC:               </th> <td>  -539.0</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>  1753</td>      <th>  BIC:               </th> <td>  -495.2</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>   -0.0217</td> <td>    0.019</td> <td>   -1.168</td> <td> 0.243</td> <td>   -0.058</td> <td>    0.015</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Open</th>      <td>   -0.5077</td> <td>    0.020</td> <td>  -25.693</td> <td> 0.000</td> <td>   -0.546</td> <td>   -0.469</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>High</th>      <td>    0.7643</td> <td>    0.017</td> <td>   44.469</td> <td> 0.000</td> <td>    0.731</td> <td>    0.798</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Low</th>       <td>    0.7443</td> <td>    0.017</td> <td>   43.292</td> <td> 0.000</td> <td>    0.711</td> <td>    0.778</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Compound</th>  <td>   -0.0093</td> <td>    0.024</td> <td>   -0.381</td> <td> 0.703</td> <td>   -0.057</td> <td>    0.038</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Neg</th>       <td>   -0.1510</td> <td>    0.168</td> <td>   -0.896</td> <td> 0.370</td> <td>   -0.481</td> <td>    0.180</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Neu</th>       <td>    0.0056</td> <td>    0.015</td> <td>    0.367</td> <td> 0.714</td> <td>   -0.024</td> <td>    0.035</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Pos</th>       <td>   -0.0086</td> <td>    0.146</td> <td>   -0.059</td> <td> 0.953</td> <td>   -0.295</td> <td>    0.278</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>220.868</td> <th>  Durbin-Watson:     </th> <td>   1.987</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2353.651</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.038</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 8.663</td>  <th>  Cond. No.          </th> <td>2.48e+03</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.48e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:              Adj_Close   R-squared:                       1.000\n",
              "Model:                            OLS   Adj. R-squared:                  1.000\n",
              "Method:                 Least Squares   F-statistic:                 6.119e+05\n",
              "Date:                Sun, 07 Jul 2019   Prob (F-statistic):               0.00\n",
              "Time:                        23:38:35   Log-Likelihood:                 277.50\n",
              "No. Observations:                1761   AIC:                            -539.0\n",
              "Df Residuals:                    1753   BIC:                            -495.2\n",
              "Df Model:                           7                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept     -0.0217      0.019     -1.168      0.243      -0.058       0.015\n",
              "Open          -0.5077      0.020    -25.693      0.000      -0.546      -0.469\n",
              "High           0.7643      0.017     44.469      0.000       0.731       0.798\n",
              "Low            0.7443      0.017     43.292      0.000       0.711       0.778\n",
              "Compound      -0.0093      0.024     -0.381      0.703      -0.057       0.038\n",
              "Neg           -0.1510      0.168     -0.896      0.370      -0.481       0.180\n",
              "Neu            0.0056      0.015      0.367      0.714      -0.024       0.035\n",
              "Pos           -0.0086      0.146     -0.059      0.953      -0.295       0.278\n",
              "==============================================================================\n",
              "Omnibus:                      220.868   Durbin-Watson:                   1.987\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2353.651\n",
              "Skew:                          -0.038   Prob(JB):                         0.00\n",
              "Kurtosis:                       8.663   Cond. No.                     2.48e+03\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 2.48e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEbGJDA9jDN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREDECTING THE TEST SET BASED ON THE SIMPLE LINEAR REGRESSION MODEL CREATED BY THE TRAINING SET \n",
        "y_test, X_test = dmatrices('Adj_Close ~ Open + High + Low + Compound + Neg + Neu + Pos', test_set, return_type = 'dataframe')\n",
        "pred = linreg.predict(X_test)\n",
        "#pred = model.get_prediction(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIcrl7mFkUV3",
        "colab_type": "code",
        "outputId": "7f7a0acb-746b-4a04-e1df-0c309ff92023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# EVALUATING THE MODEL\n",
        "# AND PLOT THE ERRORS\n",
        "# Errors looks to be normaly distributed with few outliers\n",
        "errors = pred - test_set['Adj_Close']\n",
        "sns.distplot(errors,kde = False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6ABgBIEOAEYQ6ABgBIEOAEb8F8lIUngogqWbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72zKnTxNyUok",
        "colab_type": "code",
        "outputId": "8d0ebf76-a97c-4087-caae-521813ca0cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Calculating the root mean square errors \n",
        "# Calculating the percentage of cases with less than 5% error\n",
        "import math\n",
        "rmse = math.sqrt((errors **2).sum()/len(test_set))\n",
        "rel_change = errors.abs() / test_set['Adj_Close']\n",
        "pred05 = (rel_change < 0.05).sum() / len(test_set)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"PRED(05):\", pred05)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.20341252937648835\n",
            "PRED(05): 0.9986772486772487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR75V18oz4In",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# THE SQUARE ERRORS AND PRED ACUARCY WAS BETTER WHEN THE CLOSE VARIABLE WAS THERE\n",
        "# WHEN REMOVED IT SHOWED MORE SQUARE ERROR AND LESS ACURACY BUT STILL THE ACUARY WAS HIGHT "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDqcy5iEwoAQ",
        "colab_type": "code",
        "outputId": "cbeb3ef6-cdd8-4e94-bb02-74e27deaab20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        }
      },
      "source": [
        "################################################################################\n",
        "# MICROSOFT LINEAR TEST 3\n",
        "# TESTING DIFFRENT PREDECTION - SIMPLE LINIER REGRESSION\n",
        "# REMOVE Sentiment analysis columns and see if it was doing better\n",
        "# SPLITING THE DATA INTO TRAINING SET AND TEST SET\n",
        "# THEN BUILDONG THE MODEL BASED ON THE TRAINING SET\n",
        "################################################################################\n",
        "#from patsy import dmatrices\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#import statsmodels.discrete.discrete_model as sm\n",
        "#import statsmodels.api as sm1\n",
        "\n",
        "train_set, test_set = train_test_split(dfMS, train_size=0.7, random_state=1)\n",
        "\n",
        "y_train, X_train = dmatrices('Adj_Close ~ Open + High + Low', train_set, return_type = 'dataframe')\n",
        "linier = sm1.OLS(y_train , X_train)\n",
        "linreg = linier.fit()\n",
        "linreg.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>Adj_Close</td>    <th>  R-squared:         </th> <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.430e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sun, 07 Jul 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>23:40:19</td>     <th>  Log-Likelihood:    </th> <td>  276.72</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>  1761</td>      <th>  AIC:               </th> <td>  -545.4</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>  1757</td>      <th>  BIC:               </th> <td>  -523.5</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>   -0.0249</td> <td>    0.018</td> <td>   -1.398</td> <td> 0.162</td> <td>   -0.060</td> <td>    0.010</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Open</th>      <td>   -0.5085</td> <td>    0.020</td> <td>  -25.786</td> <td> 0.000</td> <td>   -0.547</td> <td>   -0.470</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>High</th>      <td>    0.7649</td> <td>    0.017</td> <td>   44.572</td> <td> 0.000</td> <td>    0.731</td> <td>    0.799</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Low</th>       <td>    0.7444</td> <td>    0.017</td> <td>   43.445</td> <td> 0.000</td> <td>    0.711</td> <td>    0.778</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>221.182</td> <th>  Durbin-Watson:     </th> <td>   1.987</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2364.276</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.035</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 8.676</td>  <th>  Cond. No.          </th> <td>    299.</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:              Adj_Close   R-squared:                       1.000\n",
              "Model:                            OLS   Adj. R-squared:                  1.000\n",
              "Method:                 Least Squares   F-statistic:                 1.430e+06\n",
              "Date:                Sun, 07 Jul 2019   Prob (F-statistic):               0.00\n",
              "Time:                        23:40:19   Log-Likelihood:                 276.72\n",
              "No. Observations:                1761   AIC:                            -545.4\n",
              "Df Residuals:                    1757   BIC:                            -523.5\n",
              "Df Model:                           3                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept     -0.0249      0.018     -1.398      0.162      -0.060       0.010\n",
              "Open          -0.5085      0.020    -25.786      0.000      -0.547      -0.470\n",
              "High           0.7649      0.017     44.572      0.000       0.731       0.799\n",
              "Low            0.7444      0.017     43.445      0.000       0.711       0.778\n",
              "==============================================================================\n",
              "Omnibus:                      221.182   Durbin-Watson:                   1.987\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2364.276\n",
              "Skew:                          -0.035   Prob(JB):                         0.00\n",
              "Kurtosis:                       8.676   Cond. No.                         299.\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghoJ9FhQxlkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREDECTING THE TEST SET BASED ON THE SIMPLE LINEAR REGRESSION MODEL CREATED BY THE TRAINING SET \n",
        "y_test, X_test = dmatrices('Adj_Close ~ Open + High + Low', test_set, return_type = 'dataframe')\n",
        "pred = linreg.predict(X_test)\n",
        "#pred = model.get_prediction(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_lbN4PVxxsv",
        "colab_type": "code",
        "outputId": "9e321ebe-bb73-4280-d9fa-1fa40a695b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# EVALUATING THE MODEL\n",
        "# AND PLOT THE ERRORS\n",
        "# Errors looks to be normaly distributed with few outliers\n",
        "errors = pred - test_set['Adj_Close']\n",
        "sns.distplot(errors,kde = False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOgAYgkAHAEMQ6ABgCAIdAAxBoAOAIf4HgY5PV3zr9iAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5es8r7OBx3VY",
        "colab_type": "code",
        "outputId": "869f67dd-ff5b-480a-bf82-4b23963fceaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Calculating the root mean square errors \n",
        "# Calculating the percentage of cases with less than 5% error\n",
        "import math\n",
        "rmse = math.sqrt((errors **2).sum()/len(test_set))\n",
        "rel_change = errors.abs() / test_set['Adj_Close']\n",
        "pred05 = (rel_change < 0.05).sum() / len(test_set)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"PRED(05):\", pred05)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.20308116766549456\n",
            "PRED(05): 0.9986772486772487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwcmpdeIz71V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TEST SHOWS THAT ACCURACY WAS NOT CHANGED WHEN REMOVING THE SENTIMENT ANALYSIS COLUMNS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9ORWhP3P960",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE#\n",
        "#APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE#\n",
        "#APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE#\n",
        "#APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE##APPLE#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3fhhGDbSLWI",
        "colab_type": "code",
        "outputId": "08dc7300-f571-4743-e965-d692459ff3fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# COMPARING A DATA POINT FROM THE APPLE DATASET ON 3 DIFFRENT LINEAR REGRESSION MODELS\n",
        "# 1- WITH FINANCIAL DATA AND SENTIMENT ANALYSIS\n",
        "# 2- WITH FINANCIAL DATA AND COMPOUND SENTIMENT ONLY\n",
        "# 3- ONLY FINANCIAL DATA WITH NO SENTIMENT\n",
        "# Providing Test Data to the Linear Prediction Model to see its Prediction\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "model1 = ols('Adj_Close ~ Open + High + Low + Compound + Neg + Neu + Pos', data=dfMS).fit()\n",
        "model2 = ols('Adj_Close ~ Open + High + Low + Compound', data=dfMS).fit()\n",
        "model3 = ols('Adj_Close ~ Open + High + Low', data=dfMS).fit()\n",
        "\n",
        "test_df1 = pd.DataFrame(columns=[\"Open\" ,\"High\",\"Low\",\"Compound\",\"Neg\",\"Neu\",\"Pos\"], data=[[109.72, 110.54, 109.66, 0.7932, 0.052, 0.847, 0.101]])\n",
        "test_df2 = pd.DataFrame(columns=[\"Open\" ,\"High\",\"Low\",\"Compound\"], data=[[109.72, 110.54, 109.66, 0.7932]])\n",
        "test_df3 = pd.DataFrame(columns=[\"Open\" ,\"High\",\"Low\"], data=[[109.72, 110.54, 109.66]])\n",
        "\n",
        "mpg_pred1 = model1.predict(test_df1)\n",
        "mpg_pred2 = model2.predict(test_df2)\n",
        "mpg_pred3 = model3.predict(test_df3)\n",
        "\n",
        "print('Original Adj_Close Value:              0    110.06')\n",
        "print('First Model with sentiment:           ', mpg_pred1,'')\n",
        "print('Second Model only compound sentiment: ', mpg_pred2)\n",
        "print('Third Model no sentiment:             ',mpg_pred3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Adj_Close Value:              0    110.06\n",
            "First Model with sentiment:            0    110.347946\n",
            "dtype: float64 \n",
            "Second Model only compound sentiment:  0    110.348667\n",
            "dtype: float64\n",
            "Third Model no sentiment:              0    110.352574\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNYqqL7bOCJ4",
        "colab_type": "code",
        "outputId": "39fe1f27-0918-4ff7-e1f0-070aef8f12cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        }
      },
      "source": [
        "################################################ LINEAR REGRESSION WITH APPLE STOCK ##########################################################################\n",
        "#######APPLE################APPPLE################APPPLE####################APPLE##########################APPPLE######################APPLE##################\n",
        "################################################################################\n",
        "# APPLE LINEAR TEST 1\n",
        "# TESTING - SIMPLE LINIER REGRESSION\n",
        "# REMOVE CLOSE COLUMN AS IT IS THE SAME VALUE AS ADJ_CLOSE\n",
        "# SPLITING THE DATA INTO TRAINING SET AND TEST SET\n",
        "# THEN BUILDONG THE MODEL BASED ON THE TRAINING SET\n",
        "################################################################################\n",
        "from patsy import dmatrices\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.discrete.discrete_model as sm\n",
        "import statsmodels.api as sm1\n",
        "\n",
        "train_set, test_set = train_test_split(dfAPPL, train_size=0.7, random_state=1)\n",
        "\n",
        "y_train, X_train = dmatrices('Adj_Close ~ Open + High + Low + Compound + Neg + Neu + Pos', train_set, return_type = 'dataframe')\n",
        "linier = sm1.OLS(y_train , X_train)\n",
        "linreg = linier.fit()\n",
        "linreg.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>Adj_Close</td>    <th>  R-squared:         </th> <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.999e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Mon, 08 Jul 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>20:31:11</td>     <th>  Log-Likelihood:    </th> <td> -906.81</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>  1761</td>      <th>  AIC:               </th> <td>   1830.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>  1753</td>      <th>  BIC:               </th> <td>   1873.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>   -0.0034</td> <td>    0.038</td> <td>   -0.088</td> <td> 0.930</td> <td>   -0.079</td> <td>    0.072</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Open</th>      <td>   -0.5892</td> <td>    0.018</td> <td>  -32.305</td> <td> 0.000</td> <td>   -0.625</td> <td>   -0.553</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>High</th>      <td>    0.8292</td> <td>    0.016</td> <td>   52.758</td> <td> 0.000</td> <td>    0.798</td> <td>    0.860</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Low</th>       <td>    0.7596</td> <td>    0.015</td> <td>   51.289</td> <td> 0.000</td> <td>    0.731</td> <td>    0.789</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Compound</th>  <td>    0.0348</td> <td>    0.027</td> <td>    1.272</td> <td> 0.204</td> <td>   -0.019</td> <td>    0.088</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Neg</th>       <td>    0.5412</td> <td>    0.397</td> <td>    1.363</td> <td> 0.173</td> <td>   -0.238</td> <td>    1.320</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Neu</th>       <td>    0.0259</td> <td>    0.048</td> <td>    0.537</td> <td> 0.591</td> <td>   -0.069</td> <td>    0.121</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Pos</th>       <td>   -0.4950</td> <td>    0.343</td> <td>   -1.445</td> <td> 0.149</td> <td>   -1.167</td> <td>    0.177</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>418.972</td> <th>  Durbin-Watson:     </th> <td>   1.994</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>10598.347</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.507</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td>14.976</td>  <th>  Cond. No.          </th> <td>5.81e+03</td> \n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.81e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:              Adj_Close   R-squared:                       1.000\n",
              "Model:                            OLS   Adj. R-squared:                  1.000\n",
              "Method:                 Least Squares   F-statistic:                 1.999e+06\n",
              "Date:                Mon, 08 Jul 2019   Prob (F-statistic):               0.00\n",
              "Time:                        20:31:11   Log-Likelihood:                -906.81\n",
              "No. Observations:                1761   AIC:                             1830.\n",
              "Df Residuals:                    1753   BIC:                             1873.\n",
              "Df Model:                           7                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept     -0.0034      0.038     -0.088      0.930      -0.079       0.072\n",
              "Open          -0.5892      0.018    -32.305      0.000      -0.625      -0.553\n",
              "High           0.8292      0.016     52.758      0.000       0.798       0.860\n",
              "Low            0.7596      0.015     51.289      0.000       0.731       0.789\n",
              "Compound       0.0348      0.027      1.272      0.204      -0.019       0.088\n",
              "Neg            0.5412      0.397      1.363      0.173      -0.238       1.320\n",
              "Neu            0.0259      0.048      0.537      0.591      -0.069       0.121\n",
              "Pos           -0.4950      0.343     -1.445      0.149      -1.167       0.177\n",
              "==============================================================================\n",
              "Omnibus:                      418.972   Durbin-Watson:                   1.994\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            10598.347\n",
              "Skew:                           0.507   Prob(JB):                         0.00\n",
              "Kurtosis:                      14.976   Cond. No.                     5.81e+03\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 5.81e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plPrvHY4PDz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREDECTING THE TEST SET BASED ON THE SIMPLE LINEAR REGRESSION MODEL CREATED BY THE TRAINING SET \n",
        "y_test, X_test = dmatrices('Adj_Close ~ Open + High + Low + Compound + Neg + Neu + Pos', test_set, return_type = 'dataframe')\n",
        "pred = linreg.predict(X_test)\n",
        "#pred = model.get_prediction(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stM1BNhPPF0m",
        "colab_type": "code",
        "outputId": "014f9476-3ade-4ae9-de9e-765014b502a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# EVALUATING THE MODEL\n",
        "# AND PLOT THE ERRORS\n",
        "# Errors looks to be normaly distributed with few outliers\n",
        "errors = pred - test_set['Adj_Close']\n",
        "sns.distplot(errors,kde = False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw1H0AGA4ih4ADEfRA4Dh/gu8vLf+msFeXQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZSCn5diPTTx",
        "colab_type": "code",
        "outputId": "4fc02727-de24-47d7-8406-caafc1ec7405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Calculating the root mean square errors \n",
        "# Calculating the percentage of cases with less than 5% error\n",
        "import math\n",
        "rmse = math.sqrt((errors **2).sum()/len(test_set))\n",
        "rel_change = errors.abs() / test_set['Adj_Close']\n",
        "pred05 = (rel_change < 0.05).sum() / len(test_set)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"PRED(05):\", pred05)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.38362762504603054\n",
            "PRED(05): 0.9986772486772487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x7KQCmuQMS2",
        "colab_type": "code",
        "outputId": "27b32c10-ff0c-41b7-a9bc-ec7505cffb33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "################################################################################\n",
        "# APPLE LINEAR TEST 2\n",
        "# TESTING DIFFRENT PREDECTION - KNN REGRESSION\n",
        "# REMOVE Sentiment analysis columns and see if it was doing better\n",
        "# SPLITING THE DATA INTO TRAINING SET AND TEST SET\n",
        "# THEN BUILDONG THE MODEL BASED ON THE TRAINING SET\n",
        "################################################################################\n",
        "#from patsy import dmatrices\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#import statsmodels.discrete.discrete_model as sm\n",
        "#import statsmodels.api as sm1\n",
        "\n",
        "train_set, test_set = train_test_split(dfAPPL, train_size=0.7, random_state=1)\n",
        "\n",
        "y_train, X_train = dmatrices('Adj_Close ~ Open + High + Low', train_set, return_type = 'dataframe')\n",
        "linier = sm1.OLS(y_train , X_train)\n",
        "linreg = linier.fit()\n",
        "linreg.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>Adj_Close</td>    <th>  R-squared:         </th> <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>4.668e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Mon, 08 Jul 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>20:26:52</td>     <th>  Log-Likelihood:    </th> <td> -908.33</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>  1761</td>      <th>  AIC:               </th> <td>   1825.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>  1757</td>      <th>  BIC:               </th> <td>   1847.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>    0.0170</td> <td>    0.019</td> <td>    0.885</td> <td> 0.376</td> <td>   -0.021</td> <td>    0.055</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Open</th>      <td>   -0.5889</td> <td>    0.018</td> <td>  -32.303</td> <td> 0.000</td> <td>   -0.625</td> <td>   -0.553</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>High</th>      <td>    0.8301</td> <td>    0.016</td> <td>   52.927</td> <td> 0.000</td> <td>    0.799</td> <td>    0.861</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Low</th>       <td>    0.7584</td> <td>    0.015</td> <td>   51.344</td> <td> 0.000</td> <td>    0.729</td> <td>    0.787</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>421.673</td> <th>  Durbin-Watson:     </th> <td>   1.993</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>10587.830</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.518</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td>14.968</td>  <th>  Cond. No.          </th> <td>    283.</td> \n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:              Adj_Close   R-squared:                       1.000\n",
              "Model:                            OLS   Adj. R-squared:                  1.000\n",
              "Method:                 Least Squares   F-statistic:                 4.668e+06\n",
              "Date:                Mon, 08 Jul 2019   Prob (F-statistic):               0.00\n",
              "Time:                        20:26:52   Log-Likelihood:                -908.33\n",
              "No. Observations:                1761   AIC:                             1825.\n",
              "Df Residuals:                    1757   BIC:                             1847.\n",
              "Df Model:                           3                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept      0.0170      0.019      0.885      0.376      -0.021       0.055\n",
              "Open          -0.5889      0.018    -32.303      0.000      -0.625      -0.553\n",
              "High           0.8301      0.016     52.927      0.000       0.799       0.861\n",
              "Low            0.7584      0.015     51.344      0.000       0.729       0.787\n",
              "==============================================================================\n",
              "Omnibus:                      421.673   Durbin-Watson:                   1.993\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            10587.830\n",
              "Skew:                           0.518   Prob(JB):                         0.00\n",
              "Kurtosis:                      14.968   Cond. No.                         283.\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wFXMXqIQbVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREDECTING THE TEST SET BASED ON THE SIMPLE LINEAR REGRESSION MODEL CREATED BY THE TRAINING SET \n",
        "y_test, X_test = dmatrices('Adj_Close ~ Open + High + Low', test_set, return_type = 'dataframe')\n",
        "pred = linreg.predict(X_test)\n",
        "#pred = model.get_prediction(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGPvDtGKQkel",
        "colab_type": "code",
        "outputId": "8a9b6f13-769b-4910-f2a5-3c2d618c213f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# EVALUATING THE MODEL\n",
        "# AND PLOT THE ERRORS\n",
        "# Errors looks to be normaly distributed with few outliers\n",
        "errors = pred - test_set['Adj_Close']\n",
        "sns.distplot(errors,kde = False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CXKUfIXQrg6",
        "colab_type": "code",
        "outputId": "6970ead3-5205-4c65-d80f-f5895f1b495b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Calculating the root mean square errors \n",
        "# Calculating the percentage of cases with less than 5% error\n",
        "import math\n",
        "rmse = math.sqrt((errors **2).sum()/len(test_set))\n",
        "rel_change = errors.abs() / test_set['Adj_Close']\n",
        "pred05 = (rel_change < 0.05).sum() / len(test_set)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"PRED(05):\", pred05)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.38314398866699784\n",
            "PRED(05): 0.9986772486772487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muIms3yKQuS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#\n",
        "#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#\n",
        "#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#\n",
        "#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#\n",
        "#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#KNN REGRESSION#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njLUjmmO_arb",
        "colab_type": "code",
        "outputId": "adea65e0-336e-4d87-8962-461c3dd0052a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "################################# K NEAREST NEIGHBOR REGRESSION MODEL #######################################\n",
        "################################################################################\n",
        "# TEST 1\n",
        "# TESTING DIFFRENT PREDECTION - KNN REGRESSION\n",
        "# TEST WITH BOTH FINANCIAL DATA AND Sentiment analysis columns \n",
        "# SPLITING THE DATA INTO TRAINING SET AND TEST SET\n",
        "# THEN BUILDONG THE MODEL BASED ON THE TRAINING SET\n",
        "# USED K = 7\n",
        "################################################################################\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import neighbors\n",
        "from sklearn.metrics import mean_squared_error \n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "dfMS1 = dfMS.drop('Date', axis=1)\n",
        "\n",
        "train_set, test_set = train_test_split(dfMS1, train_size=0.7, random_state=1)\n",
        "\n",
        "x_train = train_set.drop('Adj_Close', axis=1)\n",
        "y_train = train_set['Adj_Close']\n",
        "\n",
        "x_test = test_set.drop('Adj_Close', axis = 1)\n",
        "y_test = test_set['Adj_Close']\n",
        "\n",
        "##########################################3\n",
        "#from sklearn.preprocessing import MinMaxScaler\n",
        "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "#x_train_scaled = scaler.fit_transform(x_train)\n",
        "#x_train = pd.DataFrame(x_train_scaled)\n",
        "\n",
        "#x_test_scaled = scaler.fit_transform(x_test)\n",
        "#x_test = pd.DataFrame(x_test_scaled)\n",
        "\n",
        "###########################################\n",
        "  \n",
        "model = neighbors.KNeighborsRegressor(n_neighbors = 7)\n",
        "\n",
        "model.fit(x_train, y_train)  #fit the model\n",
        "pred=model.predict(x_test) #make prediction on test set\n",
        "error = sqrt(mean_squared_error(y_test,pred)) #calculate rmse\n",
        "print('RMSE value for k= 7' , 'is:', error)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE value for k= 7 is: 0.17939743201490005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wbi-r89mBV1",
        "colab_type": "code",
        "outputId": "5969ea50-72c7-4777-e9de-67f0e0b82982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Providing Test Data to the KNN Prediction Model to see its Prediction\n",
        "test_df = pd.DataFrame(columns=[\"Open\" ,\"High\",\"Low\",\"Close\",\"Compound\",\"Neg\",\"Neu\",\"Pos\"], data=[[28.82, 29.4, 28.8, 29.4, 0, 0,0,0]])\n",
        "mpg_pred = model.predict(test_df)\n",
        "mpg_pred\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([29.28857143])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZwSCqJKuCKd",
        "colab_type": "code",
        "outputId": "1b11724c-723f-42c2-ea8e-d289ec5eb392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "################################# K NEAREST NEIGHBOR REGRESSION MODEL #######################################\n",
        "################################################################################\n",
        "# TEST 2\n",
        "# TESTING DIFFRENT PREDECTION - KNN REGRESSION\n",
        "# Removed Close Variable and TEST WITH BOTH FINANCIAL DATA AND Sentiment analysis columns \n",
        "# SPLITING THE DATA INTO TRAINING SET AND TEST SET\n",
        "# THEN BUILDONG THE MODEL BASED ON THE TRAINING SET\n",
        "# USED K = 7\n",
        "################################################################################\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import neighbors\n",
        "from sklearn.metrics import mean_squared_error \n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "dfMS1 = dfMS.drop('Date', axis=1)\n",
        "dfMS1 = dfMS1.drop('Close', axis=1)\n",
        "train_set, test_set = train_test_split(dfMS1, train_size=0.7, random_state=1)\n",
        "\n",
        "x_train = train_set.drop('Adj_Close', axis=1)\n",
        "y_train = train_set['Adj_Close']\n",
        "\n",
        "x_test = test_set.drop('Adj_Close', axis = 1)\n",
        "y_test = test_set['Adj_Close']\n",
        "\n",
        "##########################################3\n",
        "#from sklearn.preprocessing import MinMaxScaler\n",
        "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "#x_train_scaled = scaler.fit_transform(x_train)\n",
        "#x_train = pd.DataFrame(x_train_scaled)\n",
        "\n",
        "#x_test_scaled = scaler.fit_transform(x_test)\n",
        "#x_test = pd.DataFrame(x_test_scaled)\n",
        "\n",
        "###########################################\n",
        "  \n",
        "model = neighbors.KNeighborsRegressor(n_neighbors = 7)\n",
        "\n",
        "model.fit(x_train, y_train)  #fit the model\n",
        "pred=model.predict(x_test) #make prediction on test set\n",
        "error = sqrt(mean_squared_error(y_test,pred)) #calculate rmse\n",
        "print('RMSE value for k= 7' , 'is:', error)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE value for k= 7 is: 0.2928785088900476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOfvVYX6vJlF",
        "colab_type": "code",
        "outputId": "73aa96ed-31cd-461c-ff30-82f3e7717a05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Providing Test Data to the KNN Prediction Model to see its Prediction\n",
        "test_df = pd.DataFrame(columns=[\"Open\" ,\"High\",\"Low\",\"Compound\",\"Neg\",\"Neu\",\"Pos\"], data=[[28.82, 29.4, 28.8, 0, 0,0,0]])\n",
        "mpg_pred = model.predict(test_df)\n",
        "mpg_pred\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([29.14714286])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBqR4soPval1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FOUND THAT WHEN REMOVING THE CLOSE COLUMN THE ACCURACY OF PREDECTION WAS DECREASED AND THE RMSE VALUE WAS INCREASED "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}