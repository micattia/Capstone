{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micattia/Capstone/blob/master/06_Exprimental_Test_and_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHFqffosQo0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load pandas component for data science\n",
        "import pandas as pd\n",
        "\n",
        "#load Apple data \n",
        "linkAP1 = 'https://raw.githubusercontent.com/micattia/Capstone_Data/master/AppleFinalData.csv'\n",
        "dfAPPL = pd.read_csv(linkAP1)\n",
        "linkAP2 = 'https://raw.githubusercontent.com/micattia/Capstone_Data/master/AppleNewsStock.csv'\n",
        "dfAPPLnews = pd.read_csv(linkAP2)\n",
        "\n",
        "#load Microsoft data\n",
        "linkMS1 = 'https://raw.githubusercontent.com/micattia/Capstone_Data/master/MicrosoftFinalData.csv'\n",
        "dfMS = pd.read_csv(linkMS1)\n",
        "linkMS2 = 'https://raw.githubusercontent.com/micattia/Capstone_Data/master/MicrosoftNewsStock.csv'\n",
        "dfMSnews = pd.read_csv(linkMS2)\n",
        "\n",
        "# Changing Some column names for the Microsoft main data frame to:\n",
        "# 1- removed the space from the Adj Close column, so that it would not give errors with coding\n",
        "# 2- standarised all columns to start with caps lock.\n",
        "\n",
        "dfMS = dfMS.rename(index=str, columns={\"Adj Close\": \"Adj_Close\", \"compound\": \"Compound\", \"neg\": \"Neg\", \"neu\": \"Neu\", \"pos\": \"Pos\"})\n",
        "\n",
        "# Changing Some column names for the Apple main data frame to:\n",
        "# 1- removed the space from the Adj Close column, so that it would not give errors with coding\n",
        "# 2- standarised all columns to start with caps lock.\n",
        "\n",
        "dfAPPL = dfAPPL.rename(index=str, columns={\"Adj Close\": \"Adj_Close\", \"compound\": \"Compound\", \"neg\": \"Neg\", \"neu\": \"Neu\", \"pos\": \"Pos\"})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmfYH4buQu4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading required libraries \n",
        "#==========================\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.plotly as py\n",
        "import plotly.figure_factory as ff\n",
        "%matplotlib inline\n",
        "\n",
        "plt.style.use('ggplot')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvDEqui5Pg6Z",
        "colab_type": "code",
        "outputId": "6ce39ef6-5f04-4f89-a820-4ddcf5973778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "# Building a simple linier regression model and show its generated linier formula\n",
        "# removed the Close variable from the dataset since it is the same value as the Adj_Close dependant variable\n",
        "# which will lead to always have 100% accuracy\n",
        "\n",
        "from statsmodels.formula.api import ols\n",
        "model = ols('Adj_Close ~ Open + High + Low + Compound + Neg + Neu + Pos', data=dfMS)\n",
        "model = model.fit()\n",
        "print(model.params)\n",
        "#print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intercept   -0.007568\n",
            "Open        -0.524203\n",
            "High         0.760597\n",
            "Low          0.764195\n",
            "Compound    -0.005027\n",
            "Neg         -0.018313\n",
            "Neu         -0.000197\n",
            "Pos         -0.017996\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXCWV3wAPpnG",
        "colab_type": "code",
        "outputId": "375f3dd8-a92e-4b8a-96a2-27a487db18ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:              Adj_Close   R-squared:                       1.000\n",
            "Model:                            OLS   Adj. R-squared:                  1.000\n",
            "Method:                 Least Squares   F-statistic:                 8.886e+05\n",
            "Date:                Sun, 07 Jul 2019   Prob (F-statistic):               0.00\n",
            "Time:                        23:11:45   Log-Likelihood:                 410.96\n",
            "No. Observations:                2517   AIC:                            -805.9\n",
            "Df Residuals:                    2509   BIC:                            -759.3\n",
            "Df Model:                           7                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept     -0.0076      0.015     -0.495      0.621      -0.038       0.022\n",
            "Open          -0.5242      0.016    -32.035      0.000      -0.556      -0.492\n",
            "High           0.7606      0.014     52.598      0.000       0.732       0.789\n",
            "Low            0.7642      0.014     54.180      0.000       0.737       0.792\n",
            "Compound      -0.0050      0.020     -0.252      0.801      -0.044       0.034\n",
            "Neg           -0.0183      0.137     -0.134      0.894      -0.287       0.250\n",
            "Neu           -0.0002      0.013     -0.016      0.988      -0.025       0.025\n",
            "Pos           -0.0180      0.121     -0.149      0.881      -0.254       0.218\n",
            "==============================================================================\n",
            "Omnibus:                      339.193   Durbin-Watson:                   2.117\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3976.317\n",
            "Skew:                          -0.146   Prob(JB):                         0.00\n",
            "Kurtosis:                       9.151   Cond. No.                     2.43e+03\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 2.43e+03. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv_JYjwdvJfA",
        "colab_type": "code",
        "outputId": "e5d346e1-0de8-489b-81a7-6ded01421139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "# Using Anova test to compare between the two models where one have the financial data only \n",
        "# while the other have the sentiment analysis as well\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "\n",
        "model1 = ols('Adj_Close ~ Open + High + Low ', data=dfMS).fit()\n",
        "model2 = ols('Adj_Close ~ Open + High + Low + Compound + Neg + Neu + Pos', data=dfMS).fit()\n",
        "anova_result = anova_lm(model1, model2)\n",
        "print(anova_result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   df_resid         ssr  df_diff  ss_diff         F    Pr(>F)\n",
            "0    2513.0  106.338547      0.0      NaN       NaN       NaN\n",
            "1    2509.0  106.314047      4.0   0.0245  0.144548  0.965438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in greater\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in less\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:1892: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in less_equal\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1rnTZnC_RH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing the Simple Linier Regression model and see its predective values\n",
        "# in this section we created the model and did predection using some data input by hand \n",
        "#model = ols('Adj_Close ~ Open + High + Low + Close + Compound + Neg + Neu + Pos', data=dfMS).fit()\n",
        "#test_df = pd.DataFrame(columns=[\"Open\" ,\"High\",\"Low\",\"Close\",\"Compound\",\"Neg\",\"Neu\",\"Pos\"], data=[[30.14, 30.23, 30.03, 30.13, 0.126, 0.048,0.868,0.084]])\n",
        "#mpg_pred = model.get_prediction(test_df)\n",
        "#mpg_pred.conf_int(alpha=0.05)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC1hzIWrkbeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe2vs0qFjg4K",
        "colab_type": "code",
        "outputId": "997e8a63-7f62-4a29-877f-f7581b49577e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        }
      },
      "source": [
        "################################ 1- SIMPLE LINEAR REGRESSION MODELS ######################################################\n",
        "################################################################################\n",
        "# TEST 1\n",
        "# BUILDING FIRST PREDECTION MODEL - SIMPLE LINIER REGRESSION\n",
        "# TEST GIVE 100% ACURACY WITH THE CLOSE COLUMN, AS IT IS THE SAME AS ADJ_CLOSE VALUE\n",
        "# SPLITING THE DATA INTO TRAINING SET AND TEST SET\n",
        "# THEN BUILDONG THE MODEL BASED ON THE TRAINING SET\n",
        "################################################################################\n",
        "from patsy import dmatrices\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.discrete.discrete_model as sm\n",
        "import statsmodels.api as sm1\n",
        "\n",
        "train_set, test_set = train_test_split(dfMS, train_size=0.7, random_state=1)\n",
        "\n",
        "y_train, X_train = dmatrices('Adj_Close ~ Open + High + Low + Close + Compound + Neg + Neu + Pos', train_set, return_type = 'dataframe')\n",
        "linier = sm1.OLS(y_train , X_train)\n",
        "linreg = linier.fit()\n",
        "linreg.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>Adj_Close</td>    <th>  R-squared:         </th>  <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>2.113e+31</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sun, 07 Jul 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>23:12:22</td>     <th>  Log-Likelihood:    </th>  <td>  52172.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>  1761</td>      <th>  AIC:               </th> <td>-1.043e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>  1752</td>      <th>  BIC:               </th> <td>-1.043e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>-1.057e-14</td> <td> 2.95e-15</td> <td>   -3.580</td> <td> 0.000</td> <td>-1.64e-14</td> <td>-4.78e-15</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Open</th>      <td>-3.275e-15</td> <td> 3.69e-15</td> <td>   -0.887</td> <td> 0.375</td> <td>-1.05e-14</td> <td> 3.96e-15</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>High</th>      <td> 1.277e-15</td> <td> 3.99e-15</td> <td>    0.320</td> <td> 0.749</td> <td>-6.55e-15</td> <td> 9.11e-15</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Low</th>       <td> 4.226e-15</td> <td> 3.94e-15</td> <td>    1.073</td> <td> 0.283</td> <td> -3.5e-15</td> <td> 1.19e-14</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Close</th>     <td>    1.0000</td> <td>  3.8e-15</td> <td> 2.63e+14</td> <td> 0.000</td> <td>    1.000</td> <td>    1.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Compound</th>  <td> 4.552e-15</td> <td> 3.87e-15</td> <td>    1.175</td> <td> 0.240</td> <td>-3.04e-15</td> <td> 1.21e-14</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Neg</th>       <td> 3.209e-14</td> <td> 2.68e-14</td> <td>    1.196</td> <td> 0.232</td> <td>-2.05e-14</td> <td> 8.47e-14</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Neu</th>       <td> -1.18e-15</td> <td> 2.42e-15</td> <td>   -0.488</td> <td> 0.626</td> <td>-5.92e-15</td> <td> 3.56e-15</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Pos</th>       <td>-1.788e-14</td> <td> 2.33e-14</td> <td>   -0.768</td> <td> 0.443</td> <td>-6.36e-14</td> <td> 2.78e-14</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>172.856</td> <th>  Durbin-Watson:     </th> <td>   0.305</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 226.887</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.879</td>  <th>  Prob(JB):          </th> <td>5.40e-50</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.997</td>  <th>  Cond. No.          </th> <td>2.86e+03</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.86e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:              Adj_Close   R-squared:                       1.000\n",
              "Model:                            OLS   Adj. R-squared:                  1.000\n",
              "Method:                 Least Squares   F-statistic:                 2.113e+31\n",
              "Date:                Sun, 07 Jul 2019   Prob (F-statistic):               0.00\n",
              "Time:                        23:12:22   Log-Likelihood:                 52172.\n",
              "No. Observations:                1761   AIC:                        -1.043e+05\n",
              "Df Residuals:                    1752   BIC:                        -1.043e+05\n",
              "Df Model:                           8                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept  -1.057e-14   2.95e-15     -3.580      0.000   -1.64e-14   -4.78e-15\n",
              "Open       -3.275e-15   3.69e-15     -0.887      0.375   -1.05e-14    3.96e-15\n",
              "High        1.277e-15   3.99e-15      0.320      0.749   -6.55e-15    9.11e-15\n",
              "Low         4.226e-15   3.94e-15      1.073      0.283    -3.5e-15    1.19e-14\n",
              "Close          1.0000    3.8e-15   2.63e+14      0.000       1.000       1.000\n",
              "Compound    4.552e-15   3.87e-15      1.175      0.240   -3.04e-15    1.21e-14\n",
              "Neg         3.209e-14   2.68e-14      1.196      0.232   -2.05e-14    8.47e-14\n",
              "Neu         -1.18e-15   2.42e-15     -0.488      0.626   -5.92e-15    3.56e-15\n",
              "Pos        -1.788e-14   2.33e-14     -0.768      0.443   -6.36e-14    2.78e-14\n",
              "==============================================================================\n",
              "Omnibus:                      172.856   Durbin-Watson:                   0.305\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              226.887\n",
              "Skew:                          -0.879   Prob(JB):                     5.40e-50\n",
              "Kurtosis:                       2.997   Cond. No.                     2.86e+03\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 2.86e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV83yqctqhgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREDECTING THE TEST SET BASED ON THE SIMPLE LINEAR REGRESSION MODEL CREATED BY THE TRAINING SET \n",
        "y_test, X_test = dmatrices('Adj_Close ~ Open + High + Low + Close + Compound + Neg + Neu + Pos', test_set, return_type = 'dataframe')\n",
        "pred = linreg.predict(X_test)\n",
        "#pred = model.get_prediction(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bgtj67UzOII",
        "colab_type": "code",
        "outputId": "c17bd0f7-8900-4284-a725-3449b7de2fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# EVALUATING THE MODEL\n",
        "# AND PLOT THE ERRORS\n",
        "errors = pred - test_set['Adj_Close']\n",
        "sns.distplot(errors,kde = False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEJCAYAAACaFuz/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL46MwGYzVc5",
        "colab_type": "code",
        "outputId": "a003cd83-9901-4553-cbd0-5dac949bab39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Calculating the root mean square errors \n",
        "# Calculating the percentage of cases with less than 5% error\n",
        "import math\n",
        "rmse = math.sqrt((errors **2).sum()/len(test_set))\n",
        "rel_change = errors.abs() / test_set['Adj_Close']\n",
        "pred05 = (rel_change < 0.05).sum() / len(test_set)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"PRED(05):\", pred05)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 3.295012163886266e-14\n",
            "PRED(05): 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32dJaLqdi_Gv",
        "colab_type": "code",
        "outputId": "793c6cba-50e7-4767-b241-0202b28b9e62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "################################################################################\n",
        "# TEST 2\n",
        "# TESTING DIFFRENT PREDECTION - SIMPLE LINIER REGRESSION\n",
        "# REMOVE CLOSE COLUMN AS IT IS THE SAME VALUE AS ADJ_CLOSE\n",
        "# TEST SHOWS WHEN REMOVING THE ACCURACY WAS DECREASED \n",
        "# SPLITING THE DATA INTO TRAINING SET AND TEST SET\n",
        "# THEN BUILDONG THE MODEL BASED ON THE TRAINING SET\n",
        "################################################################################\n",
        "#from patsy import dmatrices\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#import statsmodels.discrete.discrete_model as sm\n",
        "#import statsmodels.api as sm1\n",
        "\n",
        "train_set, test_set = train_test_split(dfMS, train_size=0.7, random_state=1)\n",
        "\n",
        "y_train, X_train = dmatrices('Adj_Close ~ Open + High + Low + Compound + Neg + Neu + Pos', train_set, return_type = 'dataframe')\n",
        "linier = sm1.OLS(y_train , X_train)\n",
        "linreg = linier.fit()\n",
        "linreg.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>Adj_Close</td>    <th>  R-squared:         </th> <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>6.119e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sun, 07 Jul 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>23:38:35</td>     <th>  Log-Likelihood:    </th> <td>  277.50</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>  1761</td>      <th>  AIC:               </th> <td>  -539.0</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>  1753</td>      <th>  BIC:               </th> <td>  -495.2</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>   -0.0217</td> <td>    0.019</td> <td>   -1.168</td> <td> 0.243</td> <td>   -0.058</td> <td>    0.015</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Open</th>      <td>   -0.5077</td> <td>    0.020</td> <td>  -25.693</td> <td> 0.000</td> <td>   -0.546</td> <td>   -0.469</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>High</th>      <td>    0.7643</td> <td>    0.017</td> <td>   44.469</td> <td> 0.000</td> <td>    0.731</td> <td>    0.798</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Low</th>       <td>    0.7443</td> <td>    0.017</td> <td>   43.292</td> <td> 0.000</td> <td>    0.711</td> <td>    0.778</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Compound</th>  <td>   -0.0093</td> <td>    0.024</td> <td>   -0.381</td> <td> 0.703</td> <td>   -0.057</td> <td>    0.038</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Neg</th>       <td>   -0.1510</td> <td>    0.168</td> <td>   -0.896</td> <td> 0.370</td> <td>   -0.481</td> <td>    0.180</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Neu</th>       <td>    0.0056</td> <td>    0.015</td> <td>    0.367</td> <td> 0.714</td> <td>   -0.024</td> <td>    0.035</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Pos</th>       <td>   -0.0086</td> <td>    0.146</td> <td>   -0.059</td> <td> 0.953</td> <td>   -0.295</td> <td>    0.278</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>220.868</td> <th>  Durbin-Watson:     </th> <td>   1.987</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2353.651</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.038</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 8.663</td>  <th>  Cond. No.          </th> <td>2.48e+03</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.48e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:              Adj_Close   R-squared:                       1.000\n",
              "Model:                            OLS   Adj. R-squared:                  1.000\n",
              "Method:                 Least Squares   F-statistic:                 6.119e+05\n",
              "Date:                Sun, 07 Jul 2019   Prob (F-statistic):               0.00\n",
              "Time:                        23:38:35   Log-Likelihood:                 277.50\n",
              "No. Observations:                1761   AIC:                            -539.0\n",
              "Df Residuals:                    1753   BIC:                            -495.2\n",
              "Df Model:                           7                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept     -0.0217      0.019     -1.168      0.243      -0.058       0.015\n",
              "Open          -0.5077      0.020    -25.693      0.000      -0.546      -0.469\n",
              "High           0.7643      0.017     44.469      0.000       0.731       0.798\n",
              "Low            0.7443      0.017     43.292      0.000       0.711       0.778\n",
              "Compound      -0.0093      0.024     -0.381      0.703      -0.057       0.038\n",
              "Neg           -0.1510      0.168     -0.896      0.370      -0.481       0.180\n",
              "Neu            0.0056      0.015      0.367      0.714      -0.024       0.035\n",
              "Pos           -0.0086      0.146     -0.059      0.953      -0.295       0.278\n",
              "==============================================================================\n",
              "Omnibus:                      220.868   Durbin-Watson:                   1.987\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2353.651\n",
              "Skew:                          -0.038   Prob(JB):                         0.00\n",
              "Kurtosis:                       8.663   Cond. No.                     2.48e+03\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 2.48e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEbGJDA9jDN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREDECTING THE TEST SET BASED ON THE SIMPLE LINEAR REGRESSION MODEL CREATED BY THE TRAINING SET \n",
        "y_test, X_test = dmatrices('Adj_Close ~ Open + High + Low + Compound + Neg + Neu + Pos', test_set, return_type = 'dataframe')\n",
        "pred = linreg.predict(X_test)\n",
        "#pred = model.get_prediction(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIcrl7mFkUV3",
        "colab_type": "code",
        "outputId": "7f7a0acb-746b-4a04-e1df-0c309ff92023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# EVALUATING THE MODEL\n",
        "# AND PLOT THE ERRORS\n",
        "# Errors looks to be normaly distributed with few outliers\n",
        "errors = pred - test_set['Adj_Close']\n",
        "sns.distplot(errors,kde = False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6ABgBIEOAEYQ6ABgBIEOAEb8F8lIUngogqWbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72zKnTxNyUok",
        "colab_type": "code",
        "outputId": "8d0ebf76-a97c-4087-caae-521813ca0cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import math\n",
        "rmse = math.sqrt((errors **2).sum()/len(test_set))\n",
        "rel_change = errors.abs() / test_set['Adj_Close']\n",
        "pred05 = (rel_change < 0.05).sum() / len(test_set)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"PRED(05):\", pred05)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.20341252937648835\n",
            "PRED(05): 0.9986772486772487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR75V18oz4In",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# THE SQUARE ERRORS AND PRED ACUARCY WAS BETTER WHEN THE CLOSE VARIABLE WAS THERE\n",
        "# WHEN REMOVED IT SHOWED MORE SQUARE ERROR AND LESS ACURACY BUT STILL THE ACUARY WAS HIGHT "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDqcy5iEwoAQ",
        "colab_type": "code",
        "outputId": "cbeb3ef6-cdd8-4e94-bb02-74e27deaab20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        }
      },
      "source": [
        "################################################################################\n",
        "# TEST 3\n",
        "# TESTING DIFFRENT PREDECTION - SIMPLE LINIER REGRESSION\n",
        "# REMOVE Sentiment analysis columns and see if it was doing better\n",
        "# SPLITING THE DATA INTO TRAINING SET AND TEST SET\n",
        "# THEN BUILDONG THE MODEL BASED ON THE TRAINING SET\n",
        "################################################################################\n",
        "#from patsy import dmatrices\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#import statsmodels.discrete.discrete_model as sm\n",
        "#import statsmodels.api as sm1\n",
        "\n",
        "train_set, test_set = train_test_split(dfMS, train_size=0.7, random_state=1)\n",
        "\n",
        "y_train, X_train = dmatrices('Adj_Close ~ Open + High + Low', train_set, return_type = 'dataframe')\n",
        "linier = sm1.OLS(y_train , X_train)\n",
        "linreg = linier.fit()\n",
        "linreg.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>Adj_Close</td>    <th>  R-squared:         </th> <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.430e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sun, 07 Jul 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>23:40:19</td>     <th>  Log-Likelihood:    </th> <td>  276.72</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>  1761</td>      <th>  AIC:               </th> <td>  -545.4</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>  1757</td>      <th>  BIC:               </th> <td>  -523.5</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>   -0.0249</td> <td>    0.018</td> <td>   -1.398</td> <td> 0.162</td> <td>   -0.060</td> <td>    0.010</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Open</th>      <td>   -0.5085</td> <td>    0.020</td> <td>  -25.786</td> <td> 0.000</td> <td>   -0.547</td> <td>   -0.470</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>High</th>      <td>    0.7649</td> <td>    0.017</td> <td>   44.572</td> <td> 0.000</td> <td>    0.731</td> <td>    0.799</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Low</th>       <td>    0.7444</td> <td>    0.017</td> <td>   43.445</td> <td> 0.000</td> <td>    0.711</td> <td>    0.778</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>221.182</td> <th>  Durbin-Watson:     </th> <td>   1.987</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2364.276</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.035</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 8.676</td>  <th>  Cond. No.          </th> <td>    299.</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:              Adj_Close   R-squared:                       1.000\n",
              "Model:                            OLS   Adj. R-squared:                  1.000\n",
              "Method:                 Least Squares   F-statistic:                 1.430e+06\n",
              "Date:                Sun, 07 Jul 2019   Prob (F-statistic):               0.00\n",
              "Time:                        23:40:19   Log-Likelihood:                 276.72\n",
              "No. Observations:                1761   AIC:                            -545.4\n",
              "Df Residuals:                    1757   BIC:                            -523.5\n",
              "Df Model:                           3                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept     -0.0249      0.018     -1.398      0.162      -0.060       0.010\n",
              "Open          -0.5085      0.020    -25.786      0.000      -0.547      -0.470\n",
              "High           0.7649      0.017     44.572      0.000       0.731       0.799\n",
              "Low            0.7444      0.017     43.445      0.000       0.711       0.778\n",
              "==============================================================================\n",
              "Omnibus:                      221.182   Durbin-Watson:                   1.987\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2364.276\n",
              "Skew:                          -0.035   Prob(JB):                         0.00\n",
              "Kurtosis:                       8.676   Cond. No.                         299.\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghoJ9FhQxlkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREDECTING THE TEST SET BASED ON THE SIMPLE LINEAR REGRESSION MODEL CREATED BY THE TRAINING SET \n",
        "y_test, X_test = dmatrices('Adj_Close ~ Open + High + Low', test_set, return_type = 'dataframe')\n",
        "pred = linreg.predict(X_test)\n",
        "#pred = model.get_prediction(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_lbN4PVxxsv",
        "colab_type": "code",
        "outputId": "9e321ebe-bb73-4280-d9fa-1fa40a695b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# EVALUATING THE MODEL\n",
        "# AND PLOT THE ERRORS\n",
        "# Errors looks to be normaly distributed with few outliers\n",
        "errors = pred - test_set['Adj_Close']\n",
        "sns.distplot(errors,kde = False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOgAYgkAHAEMQ6ABgCAIdAAxBoAOAIf4HgY5PV3zr9iAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5es8r7OBx3VY",
        "colab_type": "code",
        "outputId": "869f67dd-ff5b-480a-bf82-4b23963fceaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import math\n",
        "rmse = math.sqrt((errors **2).sum()/len(test_set))\n",
        "rel_change = errors.abs() / test_set['Adj_Close']\n",
        "pred05 = (rel_change < 0.05).sum() / len(test_set)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"PRED(05):\", pred05)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.20308116766549456\n",
            "PRED(05): 0.9986772486772487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwcmpdeIz71V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TEST SHOWS THAR ACCURACY WAS NOT CHANGED WHEN REMOVING THE SENTIMENT ANALYSIS COLUMNS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njLUjmmO_arb",
        "colab_type": "code",
        "outputId": "adea65e0-336e-4d87-8962-461c3dd0052a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "################################# K NEAREST NEIGHBOR REGRESSION MODEL #######################################\n",
        "################################################################################\n",
        "# TEST 1\n",
        "# TESTING DIFFRENT PREDECTION - KNN REGRESSION\n",
        "# TEST WITH BOTH FINANCIAL DATA AND Sentiment analysis columns \n",
        "# SPLITING THE DATA INTO TRAINING SET AND TEST SET\n",
        "# THEN BUILDONG THE MODEL BASED ON THE TRAINING SET\n",
        "################################################################################\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import neighbors\n",
        "from sklearn.metrics import mean_squared_error \n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "dfMS1 = dfMS.drop('Date', axis=1)\n",
        "\n",
        "train_set, test_set = train_test_split(dfMS1, train_size=0.7, random_state=1)\n",
        "\n",
        "x_train = train_set.drop('Adj_Close', axis=1)\n",
        "y_train = train_set['Adj_Close']\n",
        "\n",
        "x_test = test_set.drop('Adj_Close', axis = 1)\n",
        "y_test = test_set['Adj_Close']\n",
        "\n",
        "##########################################3\n",
        "#from sklearn.preprocessing import MinMaxScaler\n",
        "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "#x_train_scaled = scaler.fit_transform(x_train)\n",
        "#x_train = pd.DataFrame(x_train_scaled)\n",
        "\n",
        "#x_test_scaled = scaler.fit_transform(x_test)\n",
        "#x_test = pd.DataFrame(x_test_scaled)\n",
        "\n",
        "###########################################\n",
        "  \n",
        "model = neighbors.KNeighborsRegressor(n_neighbors = 7)\n",
        "\n",
        "model.fit(x_train, y_train)  #fit the model\n",
        "pred=model.predict(x_test) #make prediction on test set\n",
        "error = sqrt(mean_squared_error(y_test,pred)) #calculate rmse\n",
        "print('RMSE value for k= 7' , 'is:', error)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE value for k= 7 is: 0.17939743201490005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wbi-r89mBV1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5969ea50-72c7-4777-e9de-67f0e0b82982"
      },
      "source": [
        "# Providing Test Data to the KNN Prediction Model to see its Prediction\n",
        "test_df = pd.DataFrame(columns=[\"Open\" ,\"High\",\"Low\",\"Close\",\"Compound\",\"Neg\",\"Neu\",\"Pos\"], data=[[28.82, 29.4, 28.8, 29.4, 0, 0,0,0]])\n",
        "mpg_pred = model.predict(test_df)\n",
        "mpg_pred\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([29.28857143])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}