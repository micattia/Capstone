{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micattia/Capstone/blob/master/05_Exprimental_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHFqffosQo0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load pandas component for data science\n",
        "import pandas as pd\n",
        "\n",
        "#load Apple data \n",
        "linkAP1 = 'https://raw.githubusercontent.com/micattia/Capstone_Data/master/AppleFinalData.csv'\n",
        "dfAPPL = pd.read_csv(linkAP1)\n",
        "linkAP2 = 'https://raw.githubusercontent.com/micattia/Capstone_Data/master/AppleNewsStock.csv'\n",
        "dfAPPLnews = pd.read_csv(linkAP2)\n",
        "\n",
        "#load Microsoft data\n",
        "linkMS1 = 'https://raw.githubusercontent.com/micattia/Capstone_Data/master/MicrosoftFinalData.csv'\n",
        "dfMS = pd.read_csv(linkMS1)\n",
        "linkMS2 = 'https://raw.githubusercontent.com/micattia/Capstone_Data/master/MicrosoftNewsStock.csv'\n",
        "dfMSnews = pd.read_csv(linkMS2)\n",
        "\n",
        "# Changing Some column names for the Microsoft main data frame to:\n",
        "# 1- removed the space from the Adj Close column, so that it would not give errors with coding\n",
        "# 2- standarised all columns to start with caps lock.\n",
        "\n",
        "dfMS = dfMS.rename(index=str, columns={\"Adj Close\": \"Adj_Close\", \"compound\": \"Compound\", \"neg\": \"Neg\", \"neu\": \"Neu\", \"pos\": \"Pos\"})\n",
        "\n",
        "# Changing Some column names for the Apple main data frame to:\n",
        "# 1- removed the space from the Adj Close column, so that it would not give errors with coding\n",
        "# 2- standarised all columns to start with caps lock.\n",
        "\n",
        "dfAPPL = dfAPPL.rename(index=str, columns={\"Adj Close\": \"Adj_Close\", \"compound\": \"Compound\", \"neg\": \"Neg\", \"neu\": \"Neu\", \"pos\": \"Pos\"})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmfYH4buQu4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading required libraries \n",
        "#==========================\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.plotly as py\n",
        "import plotly.figure_factory as ff\n",
        "%matplotlib inline\n",
        "\n",
        "pyplot.style.use('ggplot')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvDEqui5Pg6Z",
        "colab_type": "code",
        "outputId": "56483a97-1b56-4167-9fc1-85b06004e5f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "from statsmodels.formula.api import ols\n",
        "model = ols('Adj_Close ~ Open + High + Low + Close + Compound', data=dfMS)\n",
        "model = model.fit()\n",
        "print(model.params)\n",
        "#print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intercept   -4.535261e-14\n",
            "Open        -6.522560e-16\n",
            "High         1.665335e-16\n",
            "Low         -2.470246e-15\n",
            "Close        1.000000e+00\n",
            "Compound    -1.453698e-15\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXCWV3wAPpnG",
        "colab_type": "code",
        "outputId": "2a48fd75-bfab-4456-8a8b-cf6ffe1947e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:              Adj_Close   R-squared:                       1.000\n",
            "Model:                            OLS   Adj. R-squared:                  1.000\n",
            "Method:                 Least Squares   F-statistic:                 9.677e+29\n",
            "Date:                Wed, 03 Jul 2019   Prob (F-statistic):               0.00\n",
            "Time:                        01:54:17   Log-Likelihood:                 69641.\n",
            "No. Observations:                2517   AIC:                        -1.393e+05\n",
            "Df Residuals:                    2511   BIC:                        -1.392e+05\n",
            "Df Model:                           5                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept  -4.535e-14   1.67e-14     -2.718      0.007   -7.81e-14   -1.26e-14\n",
            "Open       -6.523e-16    2.2e-14     -0.030      0.976   -4.38e-14    4.25e-14\n",
            "High        1.665e-16   2.38e-14      0.007      0.994   -4.65e-14    4.68e-14\n",
            "Low         -2.47e-15   2.35e-14     -0.105      0.916   -4.86e-14    4.37e-14\n",
            "Close          1.0000   2.26e-14   4.42e+13      0.000       1.000       1.000\n",
            "Compound   -1.454e-15   1.13e-14     -0.128      0.898   -2.37e-14    2.08e-14\n",
            "==============================================================================\n",
            "Omnibus:                      251.581   Durbin-Watson:                   0.000\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              330.975\n",
            "Skew:                           0.885   Prob(JB):                     1.35e-72\n",
            "Kurtosis:                       2.839   Cond. No.                         593.\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv_JYjwdvJfA",
        "colab_type": "code",
        "outputId": "62f87d69-a8a4-4e0a-b755-4f63a7609e29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "# Using Anova test to \n",
        "import statsmodels.api as sm\n",
        "#from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "\n",
        "model1 = ols('Adj_Close ~ Open + High + Low + Close + Compound', data=dfMS).fit()\n",
        "model2 = ols('Adj_Close ~ Open + High + Low + Close + Compound + Neg + Neu + Pos', data=dfMS).fit()\n",
        "anova_result = anova_lm(model2)\n",
        "print(anova_result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              df        sum_sq       mean_sq             F    PR(>F)\n",
            "Open         1.0  2.632082e+05  2.632082e+05  1.108156e+31  0.000000\n",
            "High         1.0  2.442461e+02  2.442461e+02  1.028322e+28  0.000000\n",
            "Low          1.0  1.248891e+02  1.248891e+02  5.258068e+27  0.000000\n",
            "Close        1.0  1.063385e+02  1.063385e+02  4.477053e+27  0.000000\n",
            "Compound     1.0  2.523816e-27  2.523816e-27  1.062574e-01  0.744473\n",
            "Neg          1.0  2.180338e-28  2.180338e-28  9.179631e-03  0.923679\n",
            "Neu          1.0  2.268480e-27  2.268480e-27  9.550729e-02  0.757315\n",
            "Pos          1.0  3.304157e-27  3.304157e-27  1.391112e-01  0.709198\n",
            "Residual  2508.0  5.956979e-23  2.375191e-26           NaN       NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1rnTZnC_RH4",
        "colab_type": "code",
        "outputId": "25467655-0723-46b7-9cf0-7e0a01ed4921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Testing the Simple Linier Regression model and see its predective values\n",
        "# in this section we created the model and did predection using some data input by hand \n",
        "model = ols('Adj_Close ~ Open + High + Low + Close + Compound + Neg + Neu + Pos', data=dfMS).fit()\n",
        "test_df = pd.DataFrame(columns=[\"Open\" ,\"High\",\"Low\",\"Close\",\"Compound\",\"Neg\",\"Neu\",\"Pos\"], data=[[30.14, 30.23, 30.03, 30.19, 0.126, 0.048,0.868,0.084]])\n",
        "mpg_pred = model.get_prediction(test_df)\n",
        "mpg_pred.conf_int(alpha=0.05)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[30.19, 30.19]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC1hzIWrkbeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe2vs0qFjg4K",
        "colab_type": "code",
        "outputId": "fa2b4b06-e258-4f22-a94b-b4112fdc10b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        }
      },
      "source": [
        "################################################################################\n",
        "# TEST 1\n",
        "# BUILDING FIRST PREDECTION MODEL - SIMPLE LINIER REGRESSION\n",
        "# TEST GIVE 100% ACURACY WITH THE CLOSE COLUMN, AS IT IS THE SAME AS ADJ_CLOSE VALUE\n",
        "# SPLITING THE DATA INTO TRAINING SET AND TEST SET\n",
        "# THEN BUILDONG THE MODEL BASED ON THE TRAINING SET\n",
        "################################################################################\n",
        "from patsy import dmatrices\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.discrete.discrete_model as sm\n",
        "import statsmodels.api as sm1\n",
        "\n",
        "train_set, test_set = train_test_split(dfMS, train_size=0.7, random_state=1)\n",
        "\n",
        "y_train, X_train = dmatrices('Adj_Close ~ Open + High + Low + Close + Compound + Neg + Neu + Pos', train_set, return_type = 'dataframe')\n",
        "linier = sm1.OLS(y_train , X_train)\n",
        "linreg = linier.fit()\n",
        "linreg.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>Adj_Close</td>    <th>  R-squared:         </th>  <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>2.113e+31</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Wed, 03 Jul 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>03:07:59</td>     <th>  Log-Likelihood:    </th>  <td>  52172.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>  1761</td>      <th>  AIC:               </th> <td>-1.043e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>  1752</td>      <th>  BIC:               </th> <td>-1.043e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>-1.057e-14</td> <td> 2.95e-15</td> <td>   -3.580</td> <td> 0.000</td> <td>-1.64e-14</td> <td>-4.78e-15</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Open</th>      <td>-3.275e-15</td> <td> 3.69e-15</td> <td>   -0.887</td> <td> 0.375</td> <td>-1.05e-14</td> <td> 3.96e-15</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>High</th>      <td> 1.277e-15</td> <td> 3.99e-15</td> <td>    0.320</td> <td> 0.749</td> <td>-6.55e-15</td> <td> 9.11e-15</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Low</th>       <td> 4.226e-15</td> <td> 3.94e-15</td> <td>    1.073</td> <td> 0.283</td> <td> -3.5e-15</td> <td> 1.19e-14</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Close</th>     <td>    1.0000</td> <td>  3.8e-15</td> <td> 2.63e+14</td> <td> 0.000</td> <td>    1.000</td> <td>    1.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Compound</th>  <td> 4.552e-15</td> <td> 3.87e-15</td> <td>    1.175</td> <td> 0.240</td> <td>-3.04e-15</td> <td> 1.21e-14</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Neg</th>       <td> 3.209e-14</td> <td> 2.68e-14</td> <td>    1.196</td> <td> 0.232</td> <td>-2.05e-14</td> <td> 8.47e-14</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Neu</th>       <td> -1.18e-15</td> <td> 2.42e-15</td> <td>   -0.488</td> <td> 0.626</td> <td>-5.92e-15</td> <td> 3.56e-15</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Pos</th>       <td>-1.788e-14</td> <td> 2.33e-14</td> <td>   -0.768</td> <td> 0.443</td> <td>-6.36e-14</td> <td> 2.78e-14</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>172.856</td> <th>  Durbin-Watson:     </th> <td>   0.305</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 226.887</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.879</td>  <th>  Prob(JB):          </th> <td>5.40e-50</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.997</td>  <th>  Cond. No.          </th> <td>2.86e+03</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.86e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:              Adj_Close   R-squared:                       1.000\n",
              "Model:                            OLS   Adj. R-squared:                  1.000\n",
              "Method:                 Least Squares   F-statistic:                 2.113e+31\n",
              "Date:                Wed, 03 Jul 2019   Prob (F-statistic):               0.00\n",
              "Time:                        03:07:59   Log-Likelihood:                 52172.\n",
              "No. Observations:                1761   AIC:                        -1.043e+05\n",
              "Df Residuals:                    1752   BIC:                        -1.043e+05\n",
              "Df Model:                           8                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept  -1.057e-14   2.95e-15     -3.580      0.000   -1.64e-14   -4.78e-15\n",
              "Open       -3.275e-15   3.69e-15     -0.887      0.375   -1.05e-14    3.96e-15\n",
              "High        1.277e-15   3.99e-15      0.320      0.749   -6.55e-15    9.11e-15\n",
              "Low         4.226e-15   3.94e-15      1.073      0.283    -3.5e-15    1.19e-14\n",
              "Close          1.0000    3.8e-15   2.63e+14      0.000       1.000       1.000\n",
              "Compound    4.552e-15   3.87e-15      1.175      0.240   -3.04e-15    1.21e-14\n",
              "Neg         3.209e-14   2.68e-14      1.196      0.232   -2.05e-14    8.47e-14\n",
              "Neu         -1.18e-15   2.42e-15     -0.488      0.626   -5.92e-15    3.56e-15\n",
              "Pos        -1.788e-14   2.33e-14     -0.768      0.443   -6.36e-14    2.78e-14\n",
              "==============================================================================\n",
              "Omnibus:                      172.856   Durbin-Watson:                   0.305\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              226.887\n",
              "Skew:                          -0.879   Prob(JB):                     5.40e-50\n",
              "Kurtosis:                       2.997   Cond. No.                     2.86e+03\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 2.86e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV83yqctqhgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREDECTING THE TEST SET BASED ON THE SIMPLE LINEAR REGRESSION MODEL CREATED BY THE TRAINING SET \n",
        "y_test, X_test = dmatrices('Adj_Close ~ Open + High + Low + Close + Compound + Neg + Neu + Pos', test_set, return_type = 'dataframe')\n",
        "pred = linreg.predict(X_test)\n",
        "#pred = model.get_prediction(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bgtj67UzOII",
        "colab_type": "code",
        "outputId": "0c337edc-337a-42dc-818c-75bb231e2570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# EVALUATING THE MODEL\n",
        "# AND PLOT THE ERRORS\n",
        "errors = pred - test_set['Adj_Close']\n",
        "sns.distplot(errors,kde = False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEJCAYAAACaFuz/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL46MwGYzVc5",
        "colab_type": "code",
        "outputId": "38315ed2-16aa-4af2-da8a-dd4a91a5d282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import math\n",
        "rmse = math.sqrt((errors **2).sum()/len(test_set))\n",
        "rel_change = errors.abs() / test_set['Adj_Close']\n",
        "pred25 = (rel_change < 0.25).sum() / len(test_set)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"PRED(25):\", pred25)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 3.295012163886266e-14\n",
            "PRED(25): 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32dJaLqdi_Gv",
        "colab_type": "code",
        "outputId": "a6838116-29ca-47e6-bd1a-dff0a18e730a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "################################################################################\n",
        "# TEST 2\n",
        "# TESTING DIFFRENT PREDECTION - SIMPLE LINIER REGRESSION\n",
        "# REMOVE CLOSE COLUMN AS IT IS THE SAME VALUE AS ADJ_CLOSE\n",
        "# TEST SHOWS WHEN REMOVING THE ACCURACY WAS DECREASED \n",
        "# SPLITING THE DATA INTO TRAINING SET AND TEST SET\n",
        "# THEN BUILDONG THE MODEL BASED ON THE TRAINING SET\n",
        "################################################################################\n",
        "#from patsy import dmatrices\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#import statsmodels.discrete.discrete_model as sm\n",
        "#import statsmodels.api as sm1\n",
        "\n",
        "train_set, test_set = train_test_split(dfMS, train_size=0.7, random_state=1)\n",
        "\n",
        "y_train, X_train = dmatrices('Adj_Close ~ Open + High + Low + Compound + Neg + Neu + Pos', train_set, return_type = 'dataframe')\n",
        "linier = sm1.OLS(y_train , X_train)\n",
        "linreg = linier.fit()\n",
        "linreg.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>Adj_Close</td>    <th>  R-squared:         </th> <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>6.119e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Wed, 03 Jul 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>03:08:51</td>     <th>  Log-Likelihood:    </th> <td>  277.50</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>  1761</td>      <th>  AIC:               </th> <td>  -539.0</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>  1753</td>      <th>  BIC:               </th> <td>  -495.2</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>   -0.0217</td> <td>    0.019</td> <td>   -1.168</td> <td> 0.243</td> <td>   -0.058</td> <td>    0.015</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Open</th>      <td>   -0.5077</td> <td>    0.020</td> <td>  -25.693</td> <td> 0.000</td> <td>   -0.546</td> <td>   -0.469</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>High</th>      <td>    0.7643</td> <td>    0.017</td> <td>   44.469</td> <td> 0.000</td> <td>    0.731</td> <td>    0.798</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Low</th>       <td>    0.7443</td> <td>    0.017</td> <td>   43.292</td> <td> 0.000</td> <td>    0.711</td> <td>    0.778</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Compound</th>  <td>   -0.0093</td> <td>    0.024</td> <td>   -0.381</td> <td> 0.703</td> <td>   -0.057</td> <td>    0.038</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Neg</th>       <td>   -0.1510</td> <td>    0.168</td> <td>   -0.896</td> <td> 0.370</td> <td>   -0.481</td> <td>    0.180</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Neu</th>       <td>    0.0056</td> <td>    0.015</td> <td>    0.367</td> <td> 0.714</td> <td>   -0.024</td> <td>    0.035</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Pos</th>       <td>   -0.0086</td> <td>    0.146</td> <td>   -0.059</td> <td> 0.953</td> <td>   -0.295</td> <td>    0.278</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>220.868</td> <th>  Durbin-Watson:     </th> <td>   1.987</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2353.651</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.038</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 8.663</td>  <th>  Cond. No.          </th> <td>2.48e+03</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.48e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:              Adj_Close   R-squared:                       1.000\n",
              "Model:                            OLS   Adj. R-squared:                  1.000\n",
              "Method:                 Least Squares   F-statistic:                 6.119e+05\n",
              "Date:                Wed, 03 Jul 2019   Prob (F-statistic):               0.00\n",
              "Time:                        03:08:51   Log-Likelihood:                 277.50\n",
              "No. Observations:                1761   AIC:                            -539.0\n",
              "Df Residuals:                    1753   BIC:                            -495.2\n",
              "Df Model:                           7                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept     -0.0217      0.019     -1.168      0.243      -0.058       0.015\n",
              "Open          -0.5077      0.020    -25.693      0.000      -0.546      -0.469\n",
              "High           0.7643      0.017     44.469      0.000       0.731       0.798\n",
              "Low            0.7443      0.017     43.292      0.000       0.711       0.778\n",
              "Compound      -0.0093      0.024     -0.381      0.703      -0.057       0.038\n",
              "Neg           -0.1510      0.168     -0.896      0.370      -0.481       0.180\n",
              "Neu            0.0056      0.015      0.367      0.714      -0.024       0.035\n",
              "Pos           -0.0086      0.146     -0.059      0.953      -0.295       0.278\n",
              "==============================================================================\n",
              "Omnibus:                      220.868   Durbin-Watson:                   1.987\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2353.651\n",
              "Skew:                          -0.038   Prob(JB):                         0.00\n",
              "Kurtosis:                       8.663   Cond. No.                     2.48e+03\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 2.48e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEbGJDA9jDN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREDECTING THE TEST SET BASED ON THE SIMPLE LINEAR REGRESSION MODEL CREATED BY THE TRAINING SET \n",
        "y_test, X_test = dmatrices('Adj_Close ~ Open + High + Low + Compound + Neg + Neu + Pos', test_set, return_type = 'dataframe')\n",
        "pred = linreg.predict(X_test)\n",
        "#pred = model.get_prediction(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIcrl7mFkUV3",
        "colab_type": "code",
        "outputId": "538da53b-4b15-4ca4-c067-779992d2ff88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# EVALUATING THE MODEL\n",
        "# AND PLOT THE ERRORS\n",
        "errors = pred - test_set['Adj_Close']\n",
        "sns.distplot(errors,kde = False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6ABgBIEOAEYQ6ABgBIEOAEb8F8lIUngogqWbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72zKnTxNyUok",
        "colab_type": "code",
        "outputId": "3fd6ce9e-be62-435c-929d-e1181f5dd219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import math\n",
        "rmse = math.sqrt((errors **2).sum()/len(test_set))\n",
        "rel_change = errors.abs() / test_set['Adj_Close']\n",
        "pred25 = (rel_change < 0.25).sum() / len(test_set)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"PRED(25):\", pred25)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.20341252937648835\n",
            "PRED(25): 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR75V18oz4In",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# THE SQUARE ERRORS AND PRED ACUARCY WAS BETTER WHEN THE CLOSE VARIABLE WAS THERE\n",
        "# WHEN REMOVED IT SHOWED MORE SQUARE ERROR AND LESS ACURACY BUT STILL THE ACUARY WAS HIGHT "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}